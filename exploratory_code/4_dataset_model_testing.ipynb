{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                                  Algorithms Exploration\n",
    "\n",
    "Here we'll be testing a few different supervised learning algorithms against the dataset we developed so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing the dataset\n",
    "\n",
    "import pandas as pd\n",
    "startups = pd.read_csv('data/startups_3.csv', index_col=0)\n",
    "startups[:3]\n",
    "\n",
    "X = startups.drop('acquired', 1)\n",
    "X_numeric = X.filter(regex=('(number_of|avg_).*|.*(funding_total_usd|funding_rounds|_at)'))\n",
    "X_categorical = X.filter(regex=('(Category_|state_).*'))\n",
    "X_state = X.filter(regex=('(state_).*'))\n",
    "X_category = X.filter(regex=('(Category_).*'))\n",
    "\n",
    "y = startups['acquired']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "startups_not_operating = pd.read_csv('data/startups_not_operating_3.csv', index_col=0)\n",
    "X = startups_not_operating.drop('acquired', 1)\n",
    "y = startups_not_operating['acquired']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.057245</td>\n",
       "      <td>0.120264</td>\n",
       "      <td>-0.010556</td>\n",
       "      <td>-0.018942</td>\n",
       "      <td>-0.032121</td>\n",
       "      <td>-0.011784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.087023</td>\n",
       "      <td>-0.012353</td>\n",
       "      <td>-0.062867</td>\n",
       "      <td>-0.050250</td>\n",
       "      <td>0.004071</td>\n",
       "      <td>-0.002986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.191721</td>\n",
       "      <td>0.115093</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>0.007415</td>\n",
       "      <td>0.031256</td>\n",
       "      <td>-0.055648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5\n",
       "0 -0.057245  0.120264 -0.010556 -0.018942 -0.032121 -0.011784\n",
       "1 -0.087023 -0.012353 -0.062867 -0.050250  0.004071 -0.002986\n",
       "2  0.191721  0.115093  0.004067  0.007415  0.031256 -0.055648"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=6)\n",
    "pca.fit(X_numeric)\n",
    "X_pca =  pca.transform(X_numeric)\n",
    "X_pca = pd.DataFrame(X_pca)\n",
    "X_pca[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42, return_indices=True)\n",
    "X_undersampled, y_undersampled, indices = rus.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_software = X[X['Category_Software'] == 1]\n",
    "y_software = y.loc[X_software.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5492L,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_software.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fernando\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import grid_search\n",
    "\n",
    "def run_classifier(parameters, classifier, stratify=True, new_X=None, new_y=None):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(new_X if new_X is not None else X, new_y if new_y is not None else y, test_size=0.2, random_state=42, stratify = y if stratify else None)\n",
    "    clf = grid_search.GridSearchCV(classifier, parameters, n_jobs=4, scoring='roc_auc')\n",
    "    clf.fit(X=X_train, y=y_train)\n",
    "    model = clf.best_estimator_\n",
    "    print (clf.best_score_, clf.best_params_) \n",
    "    print roc_auc_score(y_test, model.predict(X_test))\n",
    "    print pd.crosstab(y_test, model.predict(X_test), rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8356516491843838, {'max_depth': 6})\n",
      "0.526351092476\n",
      "Predicted     0    1   All\n",
      "True                      \n",
      "0          6632   58  6690\n",
      "1           780   51   831\n",
      "All        7412  109  7521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = run_classifier({'max_depth':range(5,20)}, DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.85238623633237032, {'n_estimators': 50, 'max_depth': 9, 'class_weight': 'balanced'})\n",
      "0.779468251013\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          5446  1244  6690\n",
      "1           212   619   831\n",
      "All        5658  1863  7521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = run_classifier({'max_depth':range(5,10), 'n_estimators':[50], 'class_weight':['balanced']}, RandomForestClassifier(random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.85249587347790967, {'n_estimators': 50, 'max_depth': 9, 'class_weight': 'balanced_subsample'})\n",
      "0.782035798892\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          5424  1266  6690\n",
      "1           205   626   831\n",
      "All        5629  1892  7521\n"
     ]
    }
   ],
   "source": [
    "#Subsampled\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = run_classifier({'max_depth':range(6,10), 'n_estimators':[50], 'class_weight':['balanced_subsample']}, RandomForestClassifier(random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.82797711356597792, {'kernel': 'rbf', 'C': 100, 'class_weight': 'balanced'})\n",
      "0.754569026458\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          5137  1553  6690\n",
      "1           215   616   831\n",
      "All        5352  2169  7521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "#parameters = {'kernel':['linear', 'rbf', 'poly'], 'C':[1, 10, 100, 1000], 'class_weight':['balanced']}\n",
    "parameters = {'kernel':['rbf'], 'C':[100], 'class_weight':['balanced']}\n",
    "svc_clf = run_classifier(parameters, SVC(random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.725930646088\n",
      "0.726810045706\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          4991  1699  6690\n",
      "1           243   588   831\n",
      "All        5234  2287  7521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#clf = grid_search.GridSearchCV(classifier, parameters, n_jobs=4, scoring='roc_auc')\n",
    "clf = SVC(C=1, kernel='rbf', class_weight={0:1, 1:8})\n",
    "clf.fit(X=X_train, y=y_train)\n",
    "    #model = clf.best_estimator_\n",
    "    #print (clf.best_score_, clf.best_params_) \n",
    "print roc_auc_score(y_train, clf.predict(X_train))\n",
    "print roc_auc_score(y_test, clf.predict(X_test))\n",
    "print pd.crosstab(y_test, clf.predict(X_test), rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.71566986959496537, {'n_neighbors': 5})\n",
      "0.675567158387\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          573  286   859\n",
      "1          254  550   804\n",
      "All        827  836  1663\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "parameters = {'n_neighbors':[3, 5]}\n",
    "knn_clf = run_classifier(parameters, KNeighborsClassifier(), stratify=False, new_X=X_undersampled, new_y=y_undersampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.75196387  0.77663833  0.74250558  0.73572897  0.7446668 ]\n",
      "0.666785352467\n",
      "0.659672554003\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          5574  1116  6690\n",
      "1           427   404   831\n",
      "All        6001  1520  7521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "clf = BernoulliNB()\n",
    "print cross_val_score(clf, X_train, y_train, scoring='roc_auc', cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print roc_auc_score(y_train, clf.predict(X_train))\n",
    "print roc_auc_score(y_test, clf.predict(X_test))\n",
    "print pd.crosstab(y_test, clf.predict(X_test), rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.81046854  0.81351643  0.83313246  0.83169492  0.81887942  0.81859137\n",
      "  0.81792929  0.80912285  0.81394663  0.81957325]\n",
      "0.724380124297\n",
      "0.719264973315\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          5679  1011  6690\n",
      "1           341   490   831\n",
      "All        6020  1501  7521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "clf = SGDClassifier(random_state=0, class_weight='balanced', loss='log')\n",
    "print cross_val_score(clf, X_train, y_train, scoring='roc_auc', cv=10)\n",
    "clf.fit(X_train, y_train)\n",
    "print roc_auc_score(y_train, clf.predict(X_train))\n",
    "print roc_auc_score(y_test, clf.predict(X_test))\n",
    "print pd.crosstab(y_test, clf.predict(X_test), rownames=['True'], colnames=['Predicted'], margins=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.79927523380599907, {'loss': 'log', 'l1_ratio': 0.1, 'penalty': 'l1', 'random_state': 0, 'alpha': 0.001, 'class_weight': 'balanced'})\n",
      "0.718815193753\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          5198  1492  6690\n",
      "1           282   549   831\n",
      "All        5480  2041  7521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "parameters={'l1_ratio':[0.10, 0.15, 0.20], 'alpha':[0.001, 0.0001, 0.00001, 0.000001], 'class_weight':['balanced'], 'random_state':[0], 'loss':['hinge', 'log'], 'penalty':['l2', 'l1', 'elasticnet']}\n",
    "sgd_clf = run_classifier(parameters, SGDClassifier(), stratify=True, new_X=X_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8271532874398471, {'loss': 'log', 'l1_ratio': 0.1, 'penalty': 'l1', 'random_state': 0, 'alpha': 0.001, 'class_weight': 'balanced'})\n",
      "0.755024202296\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          5288  1402  6690\n",
      "1           233   598   831\n",
      "All        5521  2000  7521\n"
     ]
    }
   ],
   "source": [
    "#SGD for Category Software\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#parameters={'l1_ratio':[0.10, 0.15, 0.20], 'alpha':[0.001, 0.0001, 0.00001, 0.000001], 'class_weight':['balanced'], 'random_state':[0], 'loss':['hinge', 'log'], 'penalty':['l2', 'l1', 'elasticnet']}\n",
    "parameters={'l1_ratio':[0.10], 'alpha':[0.001], 'class_weight':['balanced'], 'random_state':[0], 'loss':['log'], 'penalty':['l1']}\n",
    "sgd_clf = run_classifier(parameters, SGDClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.80857442131721124, {})\n",
      "0.525906439376\n",
      "Predicted     0    1   All\n",
      "True                      \n",
      "0          6618   72  6690\n",
      "1           779   52   831\n",
      "All        7397  124  7521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "parameters={}\n",
    "lr_clf = run_classifier(parameters, LogisticRegression(), stratify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "next: ignore \"ipo\" and \"closed\", work only with opearting and acquired\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.801449128334\n",
      "0.780187034909\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          5198  1492  6690\n",
      "1           180   651   831\n",
      "All        5378  2143  7521\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "clf = XGBClassifier(random_state=0, objective='multi:softmax', num_class=2)\n",
    "#print cross_val_score(clf, X_train, y_train, scoring='roc_auc', cv=3)\n",
    "clf.fit(X_train, y_train, sample_weight=y_train.replace({1:8,0:1}))\n",
    "print roc_auc_score(y_train, clf.predict(X_train))\n",
    "print roc_auc_score(y_test, clf.predict(X_test))\n",
    "print pd.crosstab(y_test, clf.predict(X_test), rownames=['True'], colnames=['Predicted'], margins=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['acquired'],eval_metric='auc', sample_weight=dtrain['acquired'].replace({1:4,0:1}))\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['acquired'].values, dtrain_predictions)\n",
    "    print \"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['acquired'], dtrain_predprob)\n",
    "    print pd.crosstab(dtrain['acquired'], dtrain_predictions, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "    print \"AUC Score (Test): %f\" % metrics.roc_auc_score(y_test, alg.predict_proba(X_test)[:,1])\n",
    "    print pd.crosstab(y_test, alg.predict(X_test), rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "                   \n",
    "    #feat_imp = pd.Series(alg.Booster().get_fscore()).sort_values(ascending=False)\n",
    "    #feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    #plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "train = X_train.join(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train = startups\n",
    "target = 'acquired'\n",
    "\n",
    "predictors = [x for x in train.columns if x not in [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fernando\\Anaconda2\\lib\\site-packages\\xgboost-0.6-py2.7.egg\\xgboost\\sklearn.py:161: DeprecationWarning: The seed parameter is deprecated as of version .6.Please use random_state instead.seed is deprecated.\n",
      "  'seed is deprecated.', DeprecationWarning)\n",
      "C:\\Users\\Fernando\\Anaconda2\\lib\\site-packages\\xgboost-0.6-py2.7.egg\\xgboost\\sklearn.py:171: DeprecationWarning: The nthread parameter is deprecated as of version .6.Please use n_jobs instead.nthread is deprecated.\n",
      "  'nthread is deprecated.', DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.8443\n",
      "AUC Score (Train): 0.877806\n",
      "Predicted      0     1    All\n",
      "True                         \n",
      "0          23081  3674  26755\n",
      "1           1010  2315   3325\n",
      "All        24091  5989  30080\n",
      "AUC Score (Test): 0.855004\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          5758   932  6690\n",
      "1           275   556   831\n",
      "All        6033  1488  7521\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=2,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "\n",
    "modelfit(XGBClassifier(), train, predictors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
